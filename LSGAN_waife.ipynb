{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LSGAN —— 最小二乘生成对抗网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as vu\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 前附 命令行参数\n",
    "这个部分是通过命令行交互时可以查看的参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n",
    "parser.add_argument('--imageSize', type=int, default=32, help='the height / width of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64, help=\"generator filter size\")\n",
    "parser.add_argument('--ndf', type=int, default=64, help=\"discriminator filter size\")\n",
    "parser.add_argument('--niter', type=int, default=100, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', default=True, action='store_true', help='enables cuda')\n",
    "parser.add_argument('--outf', default='output/', help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "# 打印参数\n",
    "print(opt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第一部分 Generator 和 Discriminator\n",
    "这个部分是生成对抗网络最重要的两个组件。此处使用了卷积神经网络"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channel_number, generator_filter_number, latent_z):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.ConvTranspose2d(latent_z, generator_filter_number * 4, kernel_size=4),\n",
    "                                    nn.BatchNorm2d(generator_filter_number * 4),\n",
    "                                    nn.ReLU())\n",
    "        # 4 x 4 子网\n",
    "        self.layer2 = nn.Sequential(nn.ConvTranspose2d(generator_filter_number * 4, generator_filter_number * 2, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(generator_filter_number * 2),\n",
    "                                    nn.ReLU())\n",
    "        # 8 x 8 子网\n",
    "        self.layer3 = nn.Sequential(nn.ConvTranspose2d(generator_filter_number * 2, generator_filter_number, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(generator_filter_number),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        # 16 x 16 子网\n",
    "        self.layer4 = nn.Sequential(nn.ConvTranspose2d(generator_filter_number, channel_number, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.Tanh())\n",
    "\n",
    "    # 构建神经网络\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channel_number, discriminator_filter_number):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # 32 x 32 子网\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(channel_number, discriminator_filter_number, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(discriminator_filter_number),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True))\n",
    "        # 16 x 16 子网\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(discriminator_filter_number, discriminator_filter_number * 2, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(discriminator_filter_number * 2),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True))\n",
    "        # 8 x 8 子网\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(discriminator_filter_number * 2, discriminator_filter_number * 4, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(discriminator_filter_number * 4),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True))\n",
    "        # 4 x 4 子网\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(discriminator_filter_number * 4, 1, kernel_size=4, stride=1, padding=0))\n",
    "\n",
    "    # 构建神经网络\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第二部分 初始化\n",
    "这部分是初始化许多参数，为训练做准备"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建文件夹，按照参数，默认为output文件夹\n",
    "# 如果没有output文件夹，那么久创建一个文件夹\n",
    "try:\n",
    "    os.makedirs(opt.outf)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# 设置随机种子，这个地方也可以手动设置\n",
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "if opt.cuda and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(opt.manualSeed)\n",
    "\n",
    "# GPU加速\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# 正则化图形变换\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(opt.imageSize),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 通过文件获取数据集\n",
    "data_dir = \"./dataset/animation/\"\n",
    "data_set = dset.ImageFolder(data_dir, data_transform)\n",
    "# 这个data.DataLoader不要修改，runtime可知！\n",
    "loader = torch.utils.data.DataLoader(data_set, batch_size=opt.batchSize, shuffle=True, num_workers=8)\n",
    "\n",
    "# 构建训练模型\n",
    "# generator中filter的数量\n",
    "input_generator_filter_number = opt.ngf\n",
    "# discriminator中filter的数量\n",
    "input_discriminator_filter_number = opt.ndf\n",
    "# 输入图像的channel\n",
    "input_channel_number = 3\n",
    "\n",
    "generator = Generator(input_channel_number, input_generator_filter_number, opt.nz)\n",
    "discriminator = Discriminator(input_channel_number, input_discriminator_filter_number)\n",
    "\n",
    "# 损失函数与优化设置\n",
    "criterion = nn.BCELoss()  # BCE => binary cross entropy\n",
    "optimizerG = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "optimizerD = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "# 全局变量\n",
    "noise = torch.FloatTensor(opt.batchSize, opt.nz, 1, 1)\n",
    "real = torch.FloatTensor(opt.batchSize, input_channel_number, opt.imageSize, opt.imageSize)\n",
    "label = torch.FloatTensor(opt.batchSize)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "noise = Variable(noise)\n",
    "real = Variable(real)\n",
    "label = Variable(label)\n",
    "\n",
    "# 如果GPU是能够使用的，那么使用GPU去训练\n",
    "if opt.cuda and torch.cuda.is_available():\n",
    "    print(\"cuda is available\")\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    noise = noise.cuda()\n",
    "    real = real.cuda()\n",
    "    label = label.cuda()\n",
    "\n",
    "# 使用list记录一下loss值\n",
    "generator_loss = []\n",
    "discriminator_loss = []\n",
    "\n",
    "# 计时器\n",
    "start_time = datetime.datetime.now()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第三部分 训练\n",
    "训练的epoch是一个超参数，这里训练的过程参考最经典的GAN就可以了"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1, opt.niter + 1):\n",
    "    for i, (images, _) in enumerate(loader):\n",
    "        # fDx\n",
    "        discriminator.zero_grad()\n",
    "        # 使用真实数据训练，这里考虑到可能最后图片一个batch的数量会小于 opt.batchSize\n",
    "        with torch.no_grad():\n",
    "            real.resize_(images.size()).copy_(images)\n",
    "            label.resize_(images.size(0)).fill_(real_label)\n",
    "\n",
    "        output = discriminator(real)\n",
    "\n",
    "        errD_real = 0.5 * torch.mean((output - label) ** 2)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # 使用虚假的数据训练\n",
    "        label.data.fill_(fake_label)\n",
    "        with torch.no_grad():\n",
    "            noise.resize_(images.size(0), opt.nz, 1, 1)\n",
    "        noise.data.normal_(0, 1)\n",
    "\n",
    "        fake = generator(noise)\n",
    "        # 在这里解离梯度，这样generator的梯度不会更新\n",
    "        output = discriminator(fake.detach())\n",
    "\n",
    "        errD_fake = 0.5 * (torch.mean((output - label)) ** 2)\n",
    "        errD_fake.backward()\n",
    "\n",
    "        errD = errD_fake + errD_real\n",
    "        optimizerD.step()\n",
    "\n",
    "        # fGx\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = discriminator(fake)\n",
    "\n",
    "        errG = 0.5 * (torch.mean(output - label) ** 2)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # 输出日志信息\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f ' % (epoch, opt.niter, i, len(loader), errD, errG))\n",
    "\n",
    "        generator_loss.append(errG)\n",
    "        discriminator_loss.append(errD)\n",
    "\n",
    "        # 可视化（每300次做一次可视化）\n",
    "        if i % 300 == 0:\n",
    "            vu.save_image(fake.data, '%s/fake_samples_epoch_%03d_iter%03d.png' % (opt.outf, epoch, i), normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # 计时结束\n",
    "end_time = datetime.datetime.now()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第四部分 输出结果"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"spent {} minutes\".format((end_time - start_time).seconds / 60))\n",
    "# 保存generator和discriminator的状态，便于读取\n",
    "torch.save(generator.state_dict(), '%s/netG.pth' % opt.outf)\n",
    "torch.save(discriminator.state_dict(), '%s/netD.pth' % opt.outf)\n",
    "\n",
    "# 绘制学习曲线\n",
    "generator_loss_numpy = []\n",
    "discriminator_loss_numpy = []\n",
    "\n",
    "# 因为CUDA tensor不能直接转换为numpy数组，所以需要先将其转换成cpu float-tensor随后再转到numpy格式\n",
    "for i in generator_loss:\n",
    "    generator_loss_numpy.append(i.data.cpu().numpy())\n",
    "\n",
    "for i in discriminator_loss:\n",
    "    discriminator_loss_numpy.append(i.data.cpu().numpy())\n",
    "\n",
    "plt.plot(generator_loss_numpy, label=\"Generator\")\n",
    "plt.plot(discriminator_loss_numpy, label=\"Discriminator\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(opt.outf + \"loss\")\n",
    "plt.close()\n",
    "\n",
    "# 将损失函数的信息存储为txt\n",
    "np.savetxt(opt.outf + \"g_loss.txt\", generator_loss_numpy)\n",
    "np.savetxt(opt.outf + \"d_loss.txt\", discriminator_loss_numpy)\n",
    "\n",
    "# 平滑loss函数曲线\n",
    "N = 100\n",
    "g_loss_smooth = np.convolve(generator_loss_numpy, np.ones((N,)) / N, mode='valid')\n",
    "d_loss_smooth = np.convolve(discriminator_loss_numpy, np.ones((N,)) / N, mode='valid')\n",
    "\n",
    "np.savetxt(opt.outf + \"g_loss_smooth.txt\", g_loss_smooth)\n",
    "np.savetxt(opt.outf + \"d_loss_smooth.txt\", d_loss_smooth)\n",
    "\n",
    "plt.plot(g_loss_smooth, label=\"Generator\")\n",
    "plt.plot(d_loss_smooth, label=\"Discriminator\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(opt.outf + \"loss(smooth)\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}