{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LSGAN —— 最小二乘生成对抗网络"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PILLOW_VERSION' from 'PIL' (/Users/shizumu/opt/anaconda3/lib/python3.9/site-packages/PIL/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackends\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcudnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mcudnn\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mdset\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mvu\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograd\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Variable\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/__init__.py:2\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datasets\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transforms\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/datasets/__init__.py:9\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msvhn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SVHN\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mphototour\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PhotoTour\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfakedata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FakeData\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msemeion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SEMEION\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01momniglot\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Omniglot\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/datasets/fakedata.py:3\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mdata\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transforms\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mFakeData\u001B[39;00m(data\u001B[38;5;241m.\u001B[39mDataset):\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124;03m\"\"\"A fake dataset that returns randomly generated images and returns them as PIL images\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     19\u001B[0m \n\u001B[1;32m     20\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/__init__.py:1\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:17\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m functional \u001B[38;5;28;01mas\u001B[39;00m F\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mversion_info \u001B[38;5;241m<\u001B[39m (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m):\n\u001B[1;32m     20\u001B[0m     Sequence \u001B[38;5;241m=\u001B[39m collections\u001B[38;5;241m.\u001B[39mSequence\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/functional.py:5\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image, ImageOps, ImageEnhance, PILLOW_VERSION\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01maccimage\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'PILLOW_VERSION' from 'PIL' (/Users/shizumu/opt/anaconda3/lib/python3.9/site-packages/PIL/__init__.py)"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as vu\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 前附 命令行参数\n",
    "这个部分是通过命令行交互时可以查看的参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n",
    "parser.add_argument('--imageSize', type=int, default=32, help='the height / width of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64, help=\"generator filter size\")\n",
    "parser.add_argument('--ndf', type=int, default=64, help=\"discriminator filter size\")\n",
    "parser.add_argument('--niter', type=int, default=200, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--outf', default='output/', help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "# 打印参数\n",
    "print(opt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第一部分 Generator 和 Discriminator\n",
    "这个部分是生成对抗网络最重要的两个组件。此处使用了卷积神经网络"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channel_number, generator_filter_number, latent_z):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.ConvTranspose2d(latent_z, generator_filter_number * 4, kernel_size=4),\n",
    "                                    nn.BatchNorm2d(generator_filter_number * 4),\n",
    "                                    nn.ReLU())\n",
    "        # 4 x 4 子网\n",
    "        self.layer2 = nn.Sequential(nn.ConvTranspose2d(generator_filter_number * 4, generator_filter_number * 2, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(generator_filter_number * 2),\n",
    "                                    nn.ReLU())\n",
    "        # 8 x 8 子网\n",
    "        self.layer3 = nn.Sequential(nn.ConvTranspose2d(generator_filter_number * 2, generator_filter_number, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(generator_filter_number),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        # 16 x 16 子网\n",
    "        self.layer4 = nn.Sequential(nn.ConvTranspose2d(generator_filter_number, channel_number, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.Tanh())\n",
    "    # 构建神经网络\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channel_number, discriminator_filter_number):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # 32 x 32 子网\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(channel_number, discriminator_filter_number, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(discriminator_filter_number),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True))\n",
    "        # 16 x 16 子网\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(discriminator_filter_number, discriminator_filter_number * 2, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(discriminator_filter_number * 2),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True))\n",
    "        # 8 x 8 子网\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(discriminator_filter_number * 2, discriminator_filter_number * 4, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(discriminator_filter_number * 4),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True))\n",
    "        # 4 x 4 子网\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(discriminator_filter_number * 4, 1, kernel_size=4, stride=1, padding=0))\n",
    "\n",
    "    # 构建神经网络\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第二部分 初始化\n",
    "这部分是初始化许多参数，为训练做准备"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建文件夹，按照参数，默认为output文件夹\n",
    "# 如果没有output文件夹，那么久创建一个文件夹\n",
    "try:\n",
    "    os.makedirs(opt.outf)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# 设置随机种子，这个地方也可以手动设置\n",
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "if opt.cuda:\n",
    "    torch.cuda.manual_seed_all(opt.manualSeed)\n",
    "\n",
    "# GPU加速\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# 正则化图形变换\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(opt.imageSize),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 通过文件获取数据集\n",
    "data_dir = \"./dataset/animation/\"\n",
    "data_set = dset.ImageFolder(data_dir, data_transform)\n",
    "# 这个data.DataLoader不要修改，runtime可知！\n",
    "loader = torch.utils.data.DataLoader(dset, batch_size=opt.batchSize, shuffle=True, num_workers=8)\n",
    "\n",
    "# 构建训练模型\n",
    "# generator中filter的数量\n",
    "input_generator_filter_number = opt.ngf\n",
    "# discriminator中filter的数量\n",
    "input_discriminator_filter_number = opt.ndf\n",
    "# 输入图像的channel\n",
    "input_channel_number = opt.nc\n",
    "\n",
    "generator = Generator(input_channel_number, input_generator_filter_number, opt.nz)\n",
    "discriminator = Discriminator(input_channel_number, input_discriminator_filter_number)\n",
    "\n",
    "# 损失函数与优化设置\n",
    "criterion = nn.BCELoss()  # BCE => binary cross entropy\n",
    "optimizerG = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "optimizerD = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "# 全局变量\n",
    "noise = torch.FloatTensor(opt.batchSize, opt.nz, 1, 1)\n",
    "real = torch.FloatTensor(opt.batchSize, input_channel_number, opt.imageSize, opt.imageSize)\n",
    "label = torch.FloatTensor(opt.batchSize)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "noise = Variable(noise)\n",
    "real = Variable(real)\n",
    "label = Variable(label)\n",
    "\n",
    "# 如果GPU是能够使用的，那么使用GPU去训练\n",
    "if opt.cuda:\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    noise = noise.cuda()\n",
    "    real = real.cuda()\n",
    "    label = label.cuda()\n",
    "\n",
    "# 使用list记录一下loss值\n",
    "generator_loss = []\n",
    "discriminator_loss = []\n",
    "\n",
    "# 计时器\n",
    "start_time = datetime.datetime.now()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第三部分 训练\n",
    "训练的epoch是一个超参数，这里训练的过程参考最经典的GAN就可以了"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1, opt.niter + 1):\n",
    "    for i, (images, _) in enumerate(loader):\n",
    "        # fDx\n",
    "        discriminator.zero_grad()\n",
    "        # 使用真实数据训练，这里考虑到可能最后图片一个batch的数量会小于 opt.batchSize\n",
    "        real.data.resize_(images.size()).copy_(images)\n",
    "        label.data.resize_(images.size(0)).fill_(real_label)\n",
    "\n",
    "        output = discriminator(real)\n",
    "\n",
    "        # LSGAN\n",
    "        errD_real = 0.5 * torch.mean((output - label) ** 2)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # 使用虚假的数据训练\n",
    "        label.data.fill_(fake_label)\n",
    "        noise.data.resize_(images.size(0), opt.nz, 1, 1)\n",
    "        noise.data.normal_(0, 1)\n",
    "\n",
    "        fake = generator(noise)\n",
    "        # 在这里解离梯度，这样generator的梯度不会更新\n",
    "        output = discriminator(fake.detach())\n",
    "\n",
    "        errD_fake = 0.5 * (torch.mean((output - label)) ** 2)  # LSGAN\n",
    "        errD_fake.backward()\n",
    "\n",
    "        errD = errD_fake + errD_real\n",
    "        optimizerD.step()\n",
    "\n",
    "        # fGx\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = discriminator(fake)\n",
    "\n",
    "        errG = 0.5 * (torch.mean(output - label) ** 2)  # LSGAN\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # 输出日志信息\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f ' % (epoch, opt.niter, i, len(loader), errD.data[0], errG.data[0]))\n",
    "\n",
    "        generator_loss.append(errG.data[0])\n",
    "        discriminator_loss.append(errD.data[0])\n",
    "\n",
    "        # 可视化（每25次做一次可视化）\n",
    "        if i % 25 == 0:\n",
    "            vu.save_image(fake.data, '%s/fake_samples_epoch_%03d_iter%03d.png' % (opt.outf, epoch, i), normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 计时结束\n",
    "end_time = datetime.datetime.now()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第四部分 输出结果"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"spent {} minutes\".format((end_time - start_time).seconds / 60))\n",
    "torch.save(generator.state_dict(), '%s/netG.pth' % opt.outf)\n",
    "torch.save(discriminator.state_dict(), '%s/netD.pth' % opt.outf)\n",
    "\n",
    "# 绘制学习曲线\n",
    "plt.plot(generator_loss, label=\"Generator\")\n",
    "plt.plot(discriminator_loss, label=\"Discriminator\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(opt.outf + \"loss\")\n",
    "plt.close()\n",
    "\n",
    "# 将损失函数的信息存储为txt\n",
    "np.savetxt(opt.outf + \"g_loss.txt\", generator_loss)\n",
    "np.savetxt(opt.outf + \"d_loss.txt\", discriminator_loss)\n",
    "\n",
    "# 平滑loss函数曲线\n",
    "N = 100\n",
    "g_loss_smooth = np.convolve(generator_loss, np.ones((N,)) / N, mode='valid')\n",
    "d_loss_smooth = np.convolve(discriminator_loss, np.ones((N,)) / N, mode='valid')\n",
    "\n",
    "np.savetxt(opt.outf + \"g_loss_smooth.txt\", g_loss_smooth)\n",
    "np.savetxt(opt.outf + \"d_loss_smooth.txt\", d_loss_smooth)\n",
    "\n",
    "plt.plot(g_loss_smooth, label=\"Generator\")\n",
    "plt.plot(d_loss_smooth, label=\"Discriminator\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(opt.outf + \"loss(smooth)\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 附录 训练后生成的老婆以及相关图"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}